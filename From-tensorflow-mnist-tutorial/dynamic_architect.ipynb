{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diputs03/AI-Studies/blob/main/From-tensorflow-mnist-tutorial/dynamic_architect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Aiming a Dynaimic Graph-structured NeuronNetwork\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sympy"
      ],
      "metadata": {
        "id": "6mXjwpToZTeV"
      },
      "id": "6mXjwpToZTeV",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Class\n",
        "class Model:\n",
        "  def relu(x) -> float:\n",
        "    if x >= 0: return x\n",
        "    else: return 0\n",
        "  def sigmoid(x) -> float:\n",
        "    return 1/(1 + np.e**(-x))\n",
        "  def linear(x) -> float:\n",
        "    return x\n",
        "  def nul(x) -> float:\n",
        "    return x\n",
        "# Neuron\n",
        "  class Neuron:\n",
        "    name = ''\n",
        "    prev, next = [], []\n",
        "    bias = 0\n",
        "    func = None\n",
        "    def __init__(self, name, prev, next, func) -> None:\n",
        "      self.name = name\n",
        "      self.prev = prev\n",
        "      self.next = next\n",
        "      self.func = func\n",
        "    def __str__(self) -> str:\n",
        "      ret = str(self.name) + '('\n",
        "      for n in self.next:\n",
        "        ret += str(n)\n",
        "      return ret + ')'\n",
        "# Model handles\n",
        "  Input_layer, Output_layer, all_neurons = [], [], []\n",
        "  links = {}\n",
        "  def __init__(self, input_size, output_size):\n",
        "    for i in range(input_size):\n",
        "      self.Input_layer += [Model.Neuron(name=f'input_{i}',\n",
        "                                        prev=[], next=[], func=Model.sigmoid)]\n",
        "    for o in range(output_size):\n",
        "      self.Output_layer += [Model.Neuron(name=f'output_{o}',\n",
        "                                         prev=[], next=[], func=Model.sigmoid)]\n",
        "    for u in self.Input_layer:\n",
        "      for v in self.Output_layer:\n",
        "        self.links[(u,v)] = 0\n",
        "        u.next.append(v)\n",
        "        v.prev.append(u)\n",
        "    self.all_neurons += self.Input_layer+self.Output_layer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.all_neurons)\n",
        "\n",
        "  def forward(self, X):\n",
        "    for x in X: assert len(x) == len(self.Input_layer), 'invalid input'\n",
        "    l = len(X)\n",
        "    stack = self.Input_layer.copy()\n",
        "# we have to cache the input in something because this is not a layered graph\n",
        "    cache, cnt = {}, {}\n",
        "    for n in self.all_neurons:\n",
        "      cache[n], cnt[n] = [0] * l, 0\n",
        "    for e in range(l):\n",
        "      for i, elem in enumerate(self.Input_layer):\n",
        "        cache[elem][e] = X[e][i]\n",
        "# stack for nodes to be pushed\n",
        "    while len(stack) != 0:\n",
        "      c = stack.pop()\n",
        "      for e in range(l):\n",
        "        cache[c][e] = c.func(cache[c][e]+c.bias)\n",
        "      for n in c.next:\n",
        "        for e in range(l):\n",
        "          cache[n][e] += self.links[(c,n)] * cache[c][e]\n",
        "        cnt[n] += 1\n",
        "        if cnt[n] == len(n.prev):\n",
        "          stack.append(n)\n",
        "    return cache\n",
        "\n",
        "  def eval(self, X):\n",
        "    cache = self.forward(X)\n",
        "    l = len(X)\n",
        "    ret = [[] for _ in range(l)]\n",
        "    for e in range(l):\n",
        "      for o in self.Output_layer:\n",
        "        ret[e] += [cache[o][e]]\n",
        "    return ret\n",
        "\n",
        "  def backward(self, X, Y, learning_rate):\n",
        "    assert len(X) == len(Y), 'invalid input'\n",
        "    for x in X: assert len(x) == len(self.Input_layer), 'invalid input'\n",
        "    for y in Y: assert len(y) == len(self.Output_layer), 'invalid input'\n",
        "    l = len(X)\n",
        "    cache = self.forward(X)\n",
        "    stack = self.Output_layer.copy()\n",
        "    delta, cnt = {}, {}\n",
        "    for n in self.all_neurons:\n",
        "      delta[n], cnt[n] = [0] * l, 0\n",
        "    for e in range(l):\n",
        "      for o, elem in enumerate(self.Output_layer):\n",
        "        delta[elem][e] = Y[e][o] - cache[elem][e]\n",
        "\n",
        "    while len(stack) != 0:\n",
        "      c = stack.pop()\n",
        "      x = sympy.symbols('x')\n",
        "      deri = sympy.diff(c.func(x), x)\n",
        "      for e in range(l):\n",
        "        delta[c][e] *= deri.evalf(subs={x: cache[c][e]})\n",
        "      for p in c.prev:\n",
        "        for e in range(l):\n",
        "          delta[p][e] += self.links[(p,c)] * delta[c][e]\n",
        "        cnt[p] += 1\n",
        "        self.links[(p,c)] += np.dot(delta[c], cache[c]) * learning_rate\n",
        "        c.bias += np.sum(delta[c], axis=0) * learning_rate\n",
        "        if cnt[p] == len(p.next):\n",
        "          stack.append(p)\n",
        "    return None\n",
        "\n",
        "  def train(self, X, Y, epochs, learning_rate):\n",
        "    l = len(X)\n",
        "    for epoch in range(epochs):\n",
        "        output = self.eval(X)\n",
        "        self.backward(X, Y, learning_rate)\n",
        "        if epoch % 40 == 0:\n",
        "            loss = 0\n",
        "            for e in range(l):\n",
        "              for o in range(len(self.Output_layer)):\n",
        "                loss += (Y[e][o]-output[e][o]) ** 2\n",
        "            loss = (loss) ** 0.5\n",
        "            print(f\"Epoch {epoch}, Loss:{loss}\")\n",
        "\n",
        "  def __str__(self):\n",
        "    ret=''\n",
        "    for i in self.Input_layer:\n",
        "      ret += i.__str__()\n",
        "    return ret\n",
        "\n",
        "# tests\n",
        "  def Add_Node(self):\n",
        "    assert(len(self.Input_layer) != 0)\n",
        "    assert(len(self.Output_layer) != 0)\n",
        "    u = self.Input_layer[0]\n",
        "    v = self.Output_layer[0]\n",
        "    self.links.pop((u, v))\n",
        "    n = Model.Neuron(name=f'mid_{0}', prev=[u], next=[v], func=Model.sigmoid)\n",
        "    self.links[(u, n)] = 1\n",
        "    self.links[(n, v)] = 1\n",
        "    self.all_neurons.append(n)\n",
        "    u.next.remove(v)\n",
        "    u.next.append(n)\n",
        "    v.prev.remove(u)\n",
        "    v.prev.append(n)\n",
        "    print('new node', n)\n",
        "\n",
        "# testing code\n",
        "mod=Model(2, 2)\n",
        "print(mod.Input_layer)\n",
        "print(mod.Output_layer)\n",
        "print(mod.eval([[1, 2], [1, 0]]))\n",
        "mod.train([[1, 2]], [[1, 0]], 800, 10)\n",
        "mod.Add_Node()\n",
        "print(mod.eval([[1, 2], [1, 0]]))\n",
        "mod.train([[1, 2]], [[1, 0]], 800, 10)\n",
        "#mod.plot()\n",
        "print(mod)"
      ],
      "metadata": {
        "id": "7wz3QvbVUsgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6a307e-cc95-4003-c34e-56f5df33f856"
      },
      "id": "7wz3QvbVUsgE",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<__main__.Model.Neuron object at 0x7a9d83f34f50>, <__main__.Model.Neuron object at 0x7a9d96e2c350>]\n",
            "[<__main__.Model.Neuron object at 0x7a9d83f37850>, <__main__.Model.Neuron object at 0x7a9d83f36950>]\n",
            "[[0.5, 0.5], [0.5, 0.5]]\n",
            "Epoch 0, Loss:0.7071067811865476\n",
            "Epoch 40, Loss:0.00543523048398142\n",
            "Epoch 80, Loss:0.00286793656265812\n",
            "Epoch 120, Loss:0.00194967013188920\n",
            "Epoch 160, Loss:0.00147724966823401\n",
            "Epoch 200, Loss:0.00118927227142813\n",
            "Epoch 240, Loss:0.000995324680317659\n",
            "Epoch 280, Loss:0.000855801043747491\n",
            "Epoch 320, Loss:0.000750604786910675\n",
            "Epoch 360, Loss:0.000668451426962564\n",
            "Epoch 400, Loss:0.000602515060154402\n",
            "Epoch 440, Loss:0.000548423997446359\n",
            "Epoch 480, Loss:0.000503248590933190\n",
            "Epoch 520, Loss:0.000464951870085756\n",
            "Epoch 560, Loss:0.000432073565181824\n",
            "Epoch 600, Loss:0.000403539483024824\n",
            "Epoch 640, Loss:0.000378541811870924\n",
            "Epoch 680, Loss:0.000356461360821204\n",
            "Epoch 720, Loss:0.000336815538100205\n",
            "Epoch 760, Loss:0.000319222647717711\n",
            "new node mid_0(output_0())\n",
            "[[0.999597375877666, 0.000247850901940954], [0.999116918604543, 0.000312179503789219]]\n",
            "Epoch 0, Loss:0.000472796207131603\n",
            "Epoch 40, Loss:0.000431419888008470\n",
            "Epoch 80, Loss:0.000397385614915254\n",
            "Epoch 120, Loss:0.000368827878402149\n",
            "Epoch 160, Loss:0.000344470841504986\n",
            "Epoch 200, Loss:0.000323411955788554\n",
            "Epoch 240, Loss:0.000304994255937640\n",
            "Epoch 280, Loss:0.000288727712787534\n",
            "Epoch 320, Loss:0.000274239010595863\n",
            "Epoch 360, Loss:0.000261238455987968\n",
            "Epoch 400, Loss:0.000249497570841557\n",
            "Epoch 440, Loss:0.000238833549950302\n",
            "Epoch 480, Loss:0.000229098247329138\n",
            "Epoch 520, Loss:0.000220170220951159\n",
            "Epoch 560, Loss:0.000211948886898404\n",
            "Epoch 600, Loss:0.000204350156243966\n",
            "Epoch 640, Loss:0.000197303132235108\n",
            "Epoch 680, Loss:0.000190747577662438\n",
            "Epoch 720, Loss:0.000184631949755824\n",
            "Epoch 760, Loss:0.000178911858803185\n",
            "input_0(output_1()mid_0(output_0()))input_1(output_0()output_1())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod.eval([[1, 2]])"
      ],
      "metadata": {
        "id": "M1Km8zYtMN8E",
        "outputId": "8198da35-ad5a-4e04-f535-70fe01bc6564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "M1Km8zYtMN8E",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.999879025057640, 0.000124435789109206]]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plotting the network, TODO://\n",
        "  def plot(self):\n",
        "    def blank_diagram(fig_width=16, fig_height=9,\n",
        "                  bg_color=\"antiquewhite\", color=\"midnightblue\"):\n",
        "      fig = plt.figure(figsize=(fig_width / 2.54, fig_height / 2.54))\n",
        "      ax = fig.add_axes((0, 0, 1, 1))\n",
        "      ax.set_xlim(0, fig_width)\n",
        "      ax.set_ylim(0, fig_height)\n",
        "      ax.set_facecolor(bg_color)\n",
        "\n",
        "      ax.tick_params(bottom=False, top=False,\n",
        "                    left=False, right=False)\n",
        "      ax.tick_params(labelbottom=False, labeltop=False,\n",
        "                    labelleft=False, labelright=False)\n",
        "\n",
        "      ax.spines[\"top\"].set_color(color)\n",
        "      ax.spines[\"bottom\"].set_color(color)\n",
        "      ax.spines[\"left\"].set_color(color)\n",
        "      ax.spines[\"right\"].set_color(color)\n",
        "      ax.spines[\"top\"].set_linewidth(4)\n",
        "      ax.spines[\"bottom\"].set_linewidth(4)\n",
        "      ax.spines[\"left\"].set_linewidth(4)\n",
        "      ax.spines[\"right\"].set_linewidth(4)\n",
        "\n",
        "      return fig, ax\n",
        "    fig, ax = blank_diagram()\n",
        "\n",
        "    centers = [(3.5, 6.5), (8, 6.5), (12.5, 6.5), (8, 2.5)]\n",
        "    radii = 1.5\n",
        "    texts = [\n",
        "        \"\\n\".join([\"My roommate\", \"is a Philistine\", \"and a boor\"]),\n",
        "        \"\\n\".join([\"My roommate\", \"ate the last\", \"of the\", \"cold cereal\"]),\n",
        "        \"\\n\".join([\"I am really\", \"really hungy\"]),\n",
        "        \"\\n\".join([\"I'm annoyed\", \"at my roommate\"]),\n",
        "    ]\n",
        "\n",
        "    # Draw circles with text in the center\n",
        "\n",
        "    for i, center in enumerate(centers):\n",
        "        x, y = center\n",
        "        theta = np.linspace(0, 2 * np.pi, 100)\n",
        "        ax.plot(\n",
        "            x + radii * np.cos(theta),\n",
        "            y + radii * np.sin(theta),\n",
        "            color=\"midnightblue\",\n",
        "        )\n",
        "        ax.text(\n",
        "            x, y,\n",
        "            texts[i],\n",
        "            horizontalalignment=\"center\",\n",
        "            verticalalignment=\"center\",\n",
        "            color=\"midnightblue\",\n",
        "        )\n",
        "\n",
        "    ax.annotate(\n",
        "        \"\",\n",
        "        (centers[1][0] - radii, centers[1][1]),\n",
        "        (centers[0][0] + radii, centers[0][1]),\n",
        "        arrowprops=dict(arrowstyle = \"-|>\"),\n",
        "    )\n",
        "    ax.annotate(\n",
        "        \"\",\n",
        "        (centers[2][0] - radii, centers[2][1]),\n",
        "        (centers[1][0] + radii, centers[1][1]),\n",
        "        arrowprops=dict(arrowstyle = \"-|>\"),\n",
        "    )\n",
        "    ax.annotate(\n",
        "        \"\",\n",
        "        (centers[3][0] - .7 * radii, centers[3][1] + .7 * radii),\n",
        "        (centers[0][0] + .7 * radii, centers[0][1] - .7 * radii),\n",
        "        arrowprops=dict(arrowstyle = \"-|>\"),\n",
        "    )\n",
        "    ax.annotate(\n",
        "        \"\",\n",
        "        (centers[3][0] + .7 * radii, centers[3][1] + .7 * radii),\n",
        "        (centers[2][0] - .7 * radii, centers[2][1] - .7 * radii),\n",
        "        arrowprops=dict(arrowstyle = \"-|>\"),\n",
        "    )\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "qivoOd1Q76HJ"
      },
      "id": "qivoOd1Q76HJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}